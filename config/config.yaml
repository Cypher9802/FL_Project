# Main configuration file for FL_Project
# Updated for high accuracy training

# Data preprocessing
window_size: 128
step_size: 64
smote_k_neighbors: 5
noise_level: 0.01
rot_std: 0.05

# Model architecture
input_features: 9
input_size: 128
num_classes: 6
lstm_hidden: 128
n_heads: 4
max_model_size_mb: 10

# Federated Learning
federated:
  rounds: 30
  local_epochs: 3
  batch_size: 32
  clients_per_round: 10

# Training
training:
  learning_rate: 0.001
  weight_decay: 1e-4
  momentum: 0.9
  max_grad_norm: 1.0
  target_accuracy: 0.95
  label_smoothing: 0.1

# Scheduler
scheduler:
  type: cyclic
  base_lr: 1e-5
  max_lr: 5e-3
  step_size_up: 200

# Privacy
privacy:
  epsilon: 8.0
  delta: 1e-5
  noise_multiplier: 1.0
  use_secure_aggregation: true
  aggregation_noise_scale: 0.1

# Paths
model_save_path: "models/federated_har_model.pt"
device: "auto"  # auto-detect cuda/mps/cpu
